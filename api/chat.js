import { GoogleGenerativeAI } from "@google/generative-ai";
// âš ï¸ ì¤‘ìš”: ì—¬ê¸°ì„œ ì´ˆê¸°í™”í•˜ì§€ ë§ˆì„¸ìš”! (ì—ëŸ¬ ì›ì¸)
// const openai = new OpenAI(...);  <-- ì§€ìš°ì„¸ìš”

const SYSTEM_PROMPT = `
# Role
ë‹¹ì‹ ì€ 'Computational Materials Science Lab'ì˜ ì§€ëŠ¥í˜• ì‹œë®¬ë ˆì´ì…˜ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ìì—°ì–´ ìš”ì²­ì„ í•´ì„í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ ì½”ë“œ(Backend)ì— ì „ë‹¬í•  **JSON íŒŒë¼ë¯¸í„°**ë¥¼ ìƒì„±í•˜ì„¸ìš”.

# Capabilities (Simulation Models)
## 1. Grain Shrinkage (ê²°ì •ë¦½ ìˆ˜ì¶•)
- simulation_type: "grain_shrinkage"
- im (int): ê²©ì í¬ê¸° (100~512). jmì€ imê³¼ ë™ì¼.
- nnn_ed (int): ì‹œê°„ ìŠ¤í… (500~5000).
- Nout (int): ì´ë¯¸ì§€ ì €ì¥ ê°„ê²©.
- driv (float): êµ¬ë™ë ¥ (0.01~1.0).

## 2. Dendrite Growth (ìˆ˜ì§€ìƒ ì„±ì¥)
- simulation_type: "dendrite_growth"
- n (int): ê²©ì í¬ê¸° (200~512).
- steps (int): ì‹œê°„ ìŠ¤í… (1000~5000).
- n_fold_symmetry (int): ëŒ€ì¹­ì„± (4 or 6).
- aniso_magnitude (float): ì´ë°©ì„± ê°•ë„ (0.05~0.4).
- latent_heat_coef (float): ì ì—´ ê³„ìˆ˜ (0.8~2.0).

# Response Rules
1. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í¬ë§·ìœ¼ë¡œë§Œ ì‘ë‹µí•  ê²ƒ.
2. Markdown block(\`\`\`)ì„ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ.

# Example Output JSON
{
  "simulation_type": "dendrite_growth",
  "params": {
    "n": 400,
    "steps": 3000,
    "n_fold_symmetry": 6,
    "aniso_magnitude": 0.15,
    "latent_heat_coef": 1.5
  },
  "reasoning": "ëˆˆì†¡ì´ ëª¨ì–‘(6íšŒ ëŒ€ì¹­)ì„ ì„ ëª…í•˜ê²Œ ë³´ê¸° ìœ„í•´ í•´ìƒë„ë¥¼ ë†’ì˜€ìŠµë‹ˆë‹¤."
}
`;

export default async function handler(req, res) {
  // POST ìš”ì²­ í™•ì¸
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  // API Key í™•ì¸
  const apiKey = process.env.GEMINI_API_KEY;
  if (!apiKey) {
    console.error("âŒ GEMINI_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì—†ìŠµë‹ˆë‹¤.");
    return res.status(500).json({ error: "Server Configuration Error" });
  }

  try {
    const { message } = req.body;
    
    // Gemini ëª¨ë¸ ì´ˆê¸°í™”
    const genAI = new GoogleGenerativeAI(apiKey);
    const model = genAI.getGenerativeModel({ 
      model: "gemini-2.5-flash-lite", 
      generationConfig: { responseMimeType: "application/json" }
    });

    // ì‹¤í–‰
    const result = await model.generateContent(`${SYSTEM_PROMPT}\n\nUser Request: ${message}`);
    const response = await result.response;
    const text = response.text();

    // ê²°ê³¼ ë°˜í™˜
    const jsonResult = JSON.parse(text);
    return res.status(200).json(jsonResult);

  } catch (error) {
    console.error("ğŸ”¥ Gemini Error:", error);
    return res.status(500).json({ error: "AI Processing Failed", details: error.message });
  }
}